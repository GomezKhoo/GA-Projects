{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f485b",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project: Drowsiness Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c40f83",
   "metadata": {},
   "source": [
    "# Content:\n",
    "\n",
    "- Capstone Project Part 1 - Deep Learning\n",
    "- Capstone Project Part 2 - Live Demo\n",
    "\n",
    "# Capstone Project Part 2 - Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3da0b3",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "One of the world's sleepiest nations is Singapore. In a recent poll, 43 cities were analyzed, and Singapore came out on top for having the least amount of sleep. Lack of sleep or low quality sleep are unacceptable. Whatever the source, a lack of sleep over an extended period of time will be detrimental to your overall wellbeing, productivity, and safety.\n",
    "\n",
    "If you've ever driven, it's likely that you've dozed off at least once. Although we don't like to admit it, there is a serious problem that must be fixed because it has detrimental impacts. One in four car accidents are the result of drowsy driving, and one in twenty-five adult drivers admit to falling asleep at the wheel in the 30 days prior. The fact that tired driving involves more than just falling asleep behind the wheel is the most alarming element.\n",
    "\n",
    "Given the significance of this problem, we believe it is essential to offer a sleepiness monitoring system, especially in the beginning to avoid accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e61fa",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "Additionally, we believe that being drowsy can negatively impact people in both professional and academic situations. College and sleep deprivation go hand in hand, but occupational exhaustion, especially while operating heavy equipment, can result in catastrophic injuries, much like when driving while intoxicated.\n",
    "\n",
    "We propose to solve this problem by developing a detection system that detects important symptoms of fatigue and raises an alarm when required. The main objective of this study is to create a sleepiness detection system that monitors the eyes; it is thought that by identifying the signs of driver fatigue early, an accident can be prevented. When this happens when drowsiness is found, a warning signal is sent to the driver to let them know. This detection device enables early identification of a reduction in driver alertness while driving and offers a noncontact technique for evaluating various levels of driver attentiveness. When this happens when weariness is found, a warning signal is sent to the driver to let them know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab953e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Packages\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance \n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from statistics import mean\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "\n",
    "from threading import Thread\n",
    "import playsound\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "p = \"68 face landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9f6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Functions\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = distance.euclidean(mouth[14], mouth[18])\n",
    "    C = distance.euclidean(mouth[12], mouth[16])\n",
    "    mar = (A ) / (C)\n",
    "    return mar\n",
    "\n",
    "def circularity(eye):\n",
    "    A = distance.euclidean(eye[1], eye[4])\n",
    "    radius  = A/2.0\n",
    "    Area = math.pi * (radius ** 2)\n",
    "    p = 0\n",
    "    p += distance.euclidean(eye[0], eye[1])\n",
    "    p += distance.euclidean(eye[1], eye[2])\n",
    "    p += distance.euclidean(eye[2], eye[3])\n",
    "    p += distance.euclidean(eye[3], eye[4])\n",
    "    p += distance.euclidean(eye[4], eye[5])\n",
    "    p += distance.euclidean(eye[5], eye[0])\n",
    "    return 4 * math.pi * Area /(p**2)\n",
    "\n",
    "def mouth_over_eye(eye):\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    mar = mouth_aspect_ratio(eye)\n",
    "    mouth_eye = mar/ear\n",
    "    return mouth_eye\n",
    "\n",
    "def lip_distance(shape):\n",
    "    top_lip = shape[50:53]\n",
    "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
    "\n",
    "    low_lip = shape[56:59]\n",
    "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
    "\n",
    "    top_mean = np.mean(top_lip, axis=0)\n",
    "    low_mean = np.mean(low_lip, axis=0)\n",
    "\n",
    "    dist = abs(top_mean[1] - low_mean[1])\n",
    "    return dist\n",
    "\n",
    "\n",
    "def average(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if i % 240 == 0 or (i+1) % 240 == 0:\n",
    "            pass\n",
    "        else: \n",
    "            average = float(y_pred[i-1] +  y_pred[i] + y_pred[i+1])/3\n",
    "            if average >= 0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393fdda",
   "metadata": {},
   "source": [
    "The first one only detect the eyes and when the eyes reach a threshold(manually set by ourselves), it will prompt that the user eyes is 'closing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa35217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def justeyes():\n",
    "    data = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Getting out image by webcam \n",
    "        _, image = cap.read()\n",
    "        # Converting the image to gray scale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        size = gray.shape\n",
    "\n",
    "        # Get faces into webcam's image\n",
    "        rects = detector(image, 0)\n",
    "\n",
    "        # For each detected face, find the landmark.\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)#converting to NumPy Array\n",
    "            # extract the left and right eye coordinates, then use the\n",
    "            # coordinates to compute the eye aspect ratio for both eyes\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            # compute the convex hull for the left and right eye, then\n",
    "            # visualize each of the eyes\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(image, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(image, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "            # check to see if the eye aspect ratio is below the blink\n",
    "            # threshold, and if so, increment the blink frame counter\n",
    "            if ear < EYE_THRESH:\n",
    "                COUNTER += 1\n",
    "                # if the eyes were closed for a sufficient number of times\n",
    "                # then show the warning\n",
    "                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                    cv2.putText(image, \"*************ALERT! EYES ClOSING! ****************\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                # otherwise, the eye aspect ratio is not below the blink\n",
    "                # threshold, so reset the counter and alarm\n",
    "            else:\n",
    "                COUNTER = 0\n",
    "        # Show the image\n",
    "        cv2.imshow(\"Output\", image)\n",
    "            \n",
    "        k = cv2.waitKey(5) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    features_test = []\n",
    "    for d in data:\n",
    "        eye = d[36:68]\n",
    "        ear = eye_aspect_ratio(eye)\n",
    "        mar = mouth_aspect_ratio(eye)\n",
    "        cir = circularity(eye)\n",
    "        mouth_eye = mouth_over_eye(eye)\n",
    "        features_test.append([ear, mar, cir, mouth_eye])\n",
    "    \n",
    "    features_test = np.array(features_test)\n",
    "    x = features_test\n",
    "    y = pd.DataFrame(x,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n",
    "    df_means = y.mean(axis=0)\n",
    "    df_std = y.std(axis=0)\n",
    "    \n",
    "    return df_means,df_std\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,400)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c38d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only a threshold value for detecting drowsiness\n",
    "EYE_THRESH = 0.22  # indicate for blink\n",
    "EYE_FRAMES = 40  # minimum of consecutive frames of blinking\n",
    "MOUTH_AR_THRESH = 1.2\n",
    "YAWN_THRESH = 32\n",
    "ALARM_ON = False\n",
    "states = []\n",
    "ear_results = []\n",
    "# grab the indexes of the facial landmarks for the mouth\n",
    "(mStart, mEnd) = (49, 68)\n",
    "\n",
    "# grab the indexes of the facial landmarks for the left and\n",
    "# right eye, respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "\n",
    "#Run Calibration\n",
    "#mean, std = justeyes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cd64a",
   "metadata": {},
   "source": [
    "Similar to the first one but this one we will include in the mouth and a 'yawn' popup will come out when the mouth is open (assuming that is a yawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addeb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouthandeyes2():\n",
    "    data = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Getting out image by webcam \n",
    "        _, image = cap.read()\n",
    "        # Converting the image to gray scale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        size = gray.shape\n",
    "\n",
    "        # Get faces into webcam's image\n",
    "        rects = detector(image, 0)\n",
    "\n",
    "        # For each detected face, find the landmark.\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            # Make the prediction and transfom it to numpy array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # Draw on our image, all the finded cordinate points (x,y) \n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "            # build features \n",
    "            eye = shape[36:68] # Extracting relevant parts (eyes to mouth)\n",
    "            # calculate ear\n",
    "            ear = eye_aspect_ratio(eye)\n",
    "            # visualize contours only of the eyes\n",
    "            leftEye  = shape[42:48]\n",
    "            rightEye = shape[36:42]\n",
    "            dist = lip_distance(shape)\n",
    "            \n",
    "            cv2.drawContours(image, [cv2.convexHull(leftEye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(image, [cv2.convexHull(rightEye)], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            lip = shape[48:60]\n",
    "            cv2.drawContours(image, [lip], -1, (0, 255, 0), 1)\n",
    "        \n",
    "            # check if ear is below defined threshold\n",
    "            if ear < EYE_THRESH:\n",
    "                    cv2.putText(image, \"Drowsiness detected!\", (10, 30), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    \n",
    "            \n",
    "        \n",
    "            # draw EAR\n",
    "            cv2.putText(image, \"EAR: {:3f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            mouth = shape[mStart:mEnd]\n",
    "            mouthMAR = mouth_aspect_ratio(mouth)\n",
    "            mar = mouthMAR\n",
    "            # compute the convex hull for the mouth, then\n",
    "            # visualize the mouth\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "\n",
    "            cv2.drawContours(image, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            cv2.putText(image, \"MAR: {:.2f}\".format(mar), (650, 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "            # Draw text if mouth is open\n",
    "            #if mar > MOUTH_AR_THRESH:\n",
    "                #cv2.putText(image, \"Yawning!\", (800, 20),\n",
    "                            #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            if dist > YAWN_THRESH:\n",
    "                cv2.putText(image, \"Yawn Alert\", (800, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        # Show the image\n",
    "        cv2.imshow(\"Output\", image)\n",
    "            \n",
    "\n",
    "        k = cv2.waitKey(5) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    features_test = []\n",
    "    for d in data:\n",
    "        eye = d[36:68]\n",
    "        ear = eye_aspect_ratio(eye)\n",
    "        mar = mouth_aspect_ratio(eye)\n",
    "        cir = circularity(eye)\n",
    "        mouth_eye = mouth_over_eye(eye)\n",
    "        features_test.append([ear, mar, cir, mouth_eye])\n",
    "    \n",
    "    features_test = np.array(features_test)\n",
    "    x = features_test\n",
    "    y = pd.DataFrame(x,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n",
    "    df_means = y.mean(axis=0)\n",
    "    df_std = y.std(axis=0)\n",
    "    \n",
    "    return df_means,df_std\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,400)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf4c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only a threshold value for detecting drowsiness\n",
    "EYE_THRESH = 0.22  # indicate for blink\n",
    "EYE_FRAMES = 40  # minimum of consecutive frames of blinking\n",
    "MOUTH_AR_THRESH = 1.2\n",
    "YAWN_THRESH = 32\n",
    "ALARM_ON = False\n",
    "states = []\n",
    "ear_results = []\n",
    "# grab the indexes of the facial landmarks for the mouth\n",
    "(mStart, mEnd) = (49, 68)\n",
    "\n",
    "#Run Calibration\n",
    "#mean, std = mouthandeyes2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # Nose tip 34\n",
    "    (0.0, -330.0, -65.0),        # Chin 9\n",
    "    (-225.0, 170.0, -135.0),     # Left eye left corner 37\n",
    "    (225.0, 170.0, -135.0),      # Right eye right corne 46\n",
    "    (-150.0, -150.0, -125.0),    # Left Mouth corner 49\n",
    "    (150.0, -150.0, -125.0)      # Right mouth corner 55\n",
    "])\n",
    "\n",
    "\n",
    "# Checks if a matrix is a valid rotation matrix.\n",
    "def isRotationMatrix(R):\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "\n",
    "# Calculates rotation matrix to euler angles\n",
    "# The result is the same as MATLAB except the order\n",
    "# of the euler angles ( x and z are swapped ).\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "\n",
    "def getHeadTiltAndCoords(size, image_points, frame_height):\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array([[focal_length, 0, center[0]], [\n",
    "        0, focal_length, center[1]], [0, 0, 1]], dtype=\"double\")\n",
    "    # print \"Camera Matrix :\\n {0}\".format(camera_matrix)\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
    "    (_, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points,\n",
    "                                                                  camera_matrix, dist_coeffs, \n",
    "                                                                  flags = cv2.SOLVEPNP_ITERATIVE)  # flags=cv2.CV_ITERATIVE)\n",
    "\n",
    "    # print \"Rotation Vector:\\n {0}\".format(rotation_vector)\n",
    "    # print \"Translation Vector:\\n {0}\".format(translation_vector)\n",
    "    # Project a 3D point (0, 0 , 1000.0) onto the image plane\n",
    "    # We use this to draw a line sticking out of the nose_end_point2D\n",
    "    (nose_end_point2D, _) = cv2.projectPoints(np.array(\n",
    "        [(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    #get rotation matrix from the rotation vector\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "\n",
    "    #calculate head tilt angle in degrees\n",
    "    head_tilt_degree = abs(\n",
    "        [-180] - np.rad2deg([rotationMatrixToEulerAngles(rotation_matrix)[0]]))\n",
    "\n",
    "    #calculate starting and ending points for the two lines for illustration\n",
    "    starting_point = (int(image_points[0][0]), int(image_points[0][1]))\n",
    "    ending_point = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    ending_point_alternate = (ending_point[0], frame_height // 2)\n",
    "\n",
    "    return head_tilt_degree, starting_point, ending_point, ending_point_alternate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615cb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouthandeyes3():\n",
    "    data = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Getting out image by webcam \n",
    "        _, frame = cap.read()\n",
    "        # Converting the image to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        size = gray.shape\n",
    "\n",
    "        # Get faces into webcam's image\n",
    "        rects = detector(frame, 0)\n",
    "        \n",
    "        \n",
    "        if len(rects) > 0:\n",
    "            text = \"{} face(s) found\".format(len(rects))\n",
    "            cv2.putText(frame, text, (10, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # compute the bounding box of the face and draw it on the\n",
    "            # frame\n",
    "            (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "            cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1)\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            # extract the left and right eye coordinates, then use the\n",
    "            # coordinates to compute the eye aspect ratio for both eyes\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            # average the eye aspect ratio together for both eyes\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            \n",
    "            dist = lip_distance(shape)\n",
    "\n",
    "            # compute the convex hull for the left and right eye, then\n",
    "            # visualize each of the eyes\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "            # check to see if the eye aspect ratio is below the blink\n",
    "            # threshold, and if so, increment the blink frame counter\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                # if the eyes were closed for a sufficient number of times\n",
    "                # then show the warning\n",
    "                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                    cv2.putText(frame, \"Eyes Closing!\", (500, 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                # otherwise, the eye aspect ratio is not below the blink\n",
    "                # threshold, so reset the counter and alarm\n",
    "            else:\n",
    "                COUNTER = 0\n",
    "\n",
    "            mouth = shape[mStart:mEnd]\n",
    "\n",
    "            mouthMAR = mouth_aspect_ratio(mouth)\n",
    "            mar = mouthMAR\n",
    "            # compute the convex hull for the mouth, then\n",
    "            # visualize the mouth\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "\n",
    "            cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (650, 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "            # Draw text if mouth is open\n",
    "            #if mar > MOUTH_AR_THRESH:\n",
    "                #cv2.putText(frame, \"Yawning!\", (800, 20),\n",
    "                            #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if dist > YAWN_THRESH:\n",
    "                cv2.putText(frame, \"Yawn Alert\", (800, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    \n",
    "            # loop over the (x, y)-coordinates for the facial landmarks\n",
    "            # and draw each of them\n",
    "            for (i, (x, y)) in enumerate(shape):\n",
    "                if i == 33:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[0] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 8:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[1] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                \n",
    "                elif i == 36:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[2] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 45:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[3] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 48:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[4] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                \n",
    "                elif i == 54:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[5] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                else:\n",
    "                    # everything to all other landmarks\n",
    "                    # write on frame in Red\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "            #Draw the determinant image points onto the person's face\n",
    "            for p in image_points:\n",
    "                cv2.circle(frame, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)\n",
    "\n",
    "            (head_tilt_degree, start_point, end_point, \n",
    "                end_point_alt) = getHeadTiltAndCoords(size, image_points, frame_height)\n",
    "\n",
    "            cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "            cv2.line(frame, start_point, end_point_alt, (0, 0, 255), 2)\n",
    "        \n",
    "            if head_tilt_degree:\n",
    "                cv2.putText(frame, 'Head Tilt Degree: ' + str(head_tilt_degree[0]), (170, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "            # extract the mouth coordinates, then use the\n",
    "            # coordinates to compute the mouth aspect ratio\n",
    "        # show the frameq\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    features_test = []\n",
    "    for d in data:\n",
    "        eye = d[36:68]\n",
    "        ear = eye_aspect_ratio(eye)\n",
    "        mar = mouth_aspect_ratio(eye)\n",
    "        cir = circularity(eye)\n",
    "        mouth_eye = mouth_over_eye(eye)\n",
    "        features_test.append([ear, mar, cir, mouth_eye])\n",
    "    \n",
    "    features_test = np.array(features_test)\n",
    "    x = features_test\n",
    "    y = pd.DataFrame(x,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n",
    "    df_means = y.mean(axis=0)\n",
    "    df_std = y.std(axis=0)\n",
    "    \n",
    "    return df_means,df_std\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,400)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938f91cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing camera...\n"
     ]
    }
   ],
   "source": [
    "# 400x225 to 1024x576\n",
    "frame_width = 1024\n",
    "frame_height = 576\n",
    "\n",
    "# Using only a threshold value for detecting drowsiness\n",
    "EYE_THRESH = 0.22  # indicate for blink\n",
    "EYE_FRAMES = 40  # minimum of consecutive frames of blinking\n",
    "MOUTH_AR_THRESH = 1.2\n",
    "YAWN_THRESH = 32\n",
    "ALARM_ON = False\n",
    "states = []\n",
    "ear_results = []\n",
    "\n",
    "EYE_AR_THRESH = 0.22\n",
    "MOUTH_AR_THRESH = 1.2\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    global COUNTER\n",
    "\n",
    "yy = main()\n",
    "\n",
    "\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "# 2D image points. If you change the image, you need to change vector\n",
    "image_points = np.array([\n",
    "    (359, 391),     # Nose tip 34\n",
    "    (399, 561),     # Chin 9\n",
    "    (337, 297),     # Left eye left corner 37\n",
    "    (513, 301),     # Right eye right corne 46\n",
    "    (345, 465),     # Left Mouth corner 49\n",
    "    (453, 469)      # Right mouth corner 55\n",
    "], dtype=\"double\")\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "# grab the indexes of the facial landmarks for the mouth\n",
    "(mStart, mEnd) = (49, 68)\n",
    "\n",
    "#Run Calibration\n",
    "#mean, std = mouthandeyes3()\n",
    "# initialize the video stream and sleep for a bit, allowing the\n",
    "# camera sensor to warm up\n",
    "print(\"[INFO] initializing camera...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca48829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouthandeyes4():\n",
    "    data = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Getting out image by webcam \n",
    "        _, frame = cap.read()\n",
    "        # Converting the image to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        size = gray.shape\n",
    "\n",
    "        # Get faces into webcam's image\n",
    "        rects = detector(frame, 0)\n",
    "        \n",
    "        \n",
    "        if len(rects) > 0:\n",
    "            text = \"{} face(s) found\".format(len(rects))\n",
    "            cv2.putText(frame, text, (10, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # compute the bounding box of the face and draw it on the\n",
    "            # frame\n",
    "            (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "            cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1)\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            # extract the left and right eye coordinates, then use the\n",
    "            # coordinates to compute the eye aspect ratio for both eyes\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            # average the eye aspect ratio together for both eyes\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            \n",
    "            dist = lip_distance(shape)\n",
    "\n",
    "            # compute the convex hull for the left and right eye, then\n",
    "            # visualize each of the eyes\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "            # check to see if the eye aspect ratio is below the blink\n",
    "            # threshold, and if so, increment the blink frame counter\n",
    "            if ear < HIGH_EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                # if the eyes were closed for a sufficient number of times\n",
    "                # then show the warning\n",
    "                if COUNTER >= HIGH_EYE_AR_CONSEC_FRAMES:\n",
    "                    cv2.putText(frame, \"High Alert!! Eyes Closing!\", (500, 40),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                # otherwise, the eye aspect ratio is not below the blink\n",
    "                    \n",
    "            elif ear < LOW_EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                # if the eyes were closed for a sufficient number of times\n",
    "                # then show the warning\n",
    "                if COUNTER >= LOW_EYE_AR_CONSEC_FRAMES:\n",
    "                    cv2.putText(frame, \"Alert! Eyes Closing!\", (500, 40),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                # otherwise, the eye aspect ratio is not below the blink\n",
    "                # threshold, so reset the counter and alarm    \n",
    "            else:\n",
    "                COUNTER = 0\n",
    "            \n",
    "\n",
    "            mouth = shape[mStart:mEnd]\n",
    "\n",
    "            mouthMAR = mouth_aspect_ratio(mouth)\n",
    "            mar = mouthMAR\n",
    "            # compute the convex hull for the mouth, then\n",
    "            # visualize the mouth\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "\n",
    "            cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (650, 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "            # Draw text if mouth is open\n",
    "            #if mar > MOUTH_AR_THRESH:\n",
    "                #cv2.putText(frame, \"Yawning!\", (800, 20),\n",
    "                            #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if dist > HIGH_YAWN_THRESH:\n",
    "                COUNT_YAWN += 1\n",
    "                # if the mouth was openedd for a sufficient number of times\n",
    "                # then show the warning\n",
    "                if COUNT_YAWN >= HIGH_COUNT_YAWN:\n",
    "                    cv2.putText(frame, \"High Alert!! Excessive Yawn Alert\", (800, 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            elif dist > LOW_YAWN_THRESH:\n",
    "                cv2.putText(frame, \"Alert!! Yawn Alert\", (800, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            else:\n",
    "                COUNT_YAWN = 0\n",
    "            \n",
    "            # loop over the (x, y)-coordinates for the facial landmarks\n",
    "            # and draw each of them\n",
    "            for (i, (x, y)) in enumerate(shape):\n",
    "                if i == 33:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[0] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 8:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[1] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                \n",
    "                elif i == 36:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[2] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 45:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[3] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                elif i == 48:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[4] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                \n",
    "                elif i == 54:\n",
    "                    # something to our key landmarks\n",
    "                    # save to our new key point list\n",
    "                    # i.e. keypoints = [(i,(x,y))]\n",
    "                    image_points[5] = np.array([x, y], dtype='double')\n",
    "                    # write on frame in Green\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "                else:\n",
    "                    # everything to all other landmarks\n",
    "                    # write on frame in Red\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "                    cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "            #Draw the determinant image points onto the person's face\n",
    "            for p in image_points:\n",
    "                cv2.circle(frame, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)\n",
    "\n",
    "            (head_tilt_degree, start_point, end_point, \n",
    "                end_point_alt) = getHeadTiltAndCoords(size, image_points, frame_height)\n",
    "\n",
    "            cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "            cv2.line(frame, start_point, end_point_alt, (0, 0, 255), 2)\n",
    "        \n",
    "            if head_tilt_degree:\n",
    "                cv2.putText(frame, 'Head Tilt Degree: ' + str(head_tilt_degree[0]), (170, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "            # extract the mouth coordinates, then use the\n",
    "            # coordinates to compute the mouth aspect ratio\n",
    "        # show the frameq\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    features_test = []\n",
    "    for d in data:\n",
    "        eye = d[36:68]\n",
    "        ear = eye_aspect_ratio(eye)\n",
    "        mar = mouth_aspect_ratio(eye)\n",
    "        cir = circularity(eye)\n",
    "        mouth_eye = mouth_over_eye(eye)\n",
    "        features_test.append([ear, mar, cir, mouth_eye])\n",
    "    \n",
    "    features_test = np.array(features_test)\n",
    "    x = features_test\n",
    "    y = pd.DataFrame(x,columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n",
    "    df_means = y.mean(axis=0)\n",
    "    df_std = y.std(axis=0)\n",
    "    \n",
    "    return df_means,df_std\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,400)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab891724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400x225 to 1024x576\n",
    "frame_width = 1024\n",
    "frame_height = 576\n",
    "\n",
    "# (Low drowsiness Mode) Using only a threshold value for detecting drowsiness\n",
    "LOW_EYE_THRESH = 0.34  # indicate for blink\n",
    "LOW_EYE_FRAMES = 40  # minimum of consecutive frames of blinking\n",
    "LOW_MOUTH_AR_THRESH = 1.2\n",
    "LOW_YAWN_THRESH = 35\n",
    "ALARM_ON = False\n",
    "states = []\n",
    "ear_results = []\n",
    "\n",
    "LOW_EYE_AR_THRESH = 0.22\n",
    "LOW_MOUTH_AR_THRESH = 1.2\n",
    "LOW_EYE_AR_CONSEC_FRAMES = 6\n",
    "LOW_COUNT_YAWN = 0\n",
    "\n",
    "\n",
    "# (High drowsiness Mode) Using only a threshold value for detecting drowsiness\n",
    "HIGH_EYE_THRESH = 0.22  # indicate for blink\n",
    "HIGH_EYE_FRAMES = 40  # minimum of consecutive frames of blinking\n",
    "HIGH_MOUTH_AR_THRESH = 1.2\n",
    "HIGH_YAWN_THRESH = 50\n",
    "ALARM_ON = False\n",
    "states = []\n",
    "ear_results = []\n",
    "\n",
    "HIGH_EYE_AR_THRESH = 0.22\n",
    "HIGH_MOUTH_AR_THRESH = 1.2\n",
    "HIGH_EYE_AR_CONSEC_FRAMES = 3\n",
    "HIGH_COUNT_YAWN = 5 \n",
    "\n",
    "\n",
    "COUNT_YAWN = 0\n",
    "\n",
    "def main():\n",
    "    global COUNTER\n",
    "\n",
    "yy = main()\n",
    "\n",
    "\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "# 2D image points. If you change the image, you need to change vector\n",
    "image_points = np.array([\n",
    "    (359, 391),     # Nose tip 34\n",
    "    (399, 561),     # Chin 9\n",
    "    (337, 297),     # Left eye left corner 37\n",
    "    (513, 301),     # Right eye right corne 46\n",
    "    (345, 465),     # Left Mouth corner 49\n",
    "    (453, 469)      # Right mouth corner 55\n",
    "], dtype=\"double\")\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "# grab the indexes of the facial landmarks for the mouth\n",
    "(mStart, mEnd) = (49, 68)\n",
    "\n",
    "#Run Calibration\n",
    "mean, std = mouthandeyes4()\n",
    "# initialize the video stream and sleep for a bit, allowing the\n",
    "# camera sensor to warm up\n",
    "print(\"[INFO] initializing camera...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
